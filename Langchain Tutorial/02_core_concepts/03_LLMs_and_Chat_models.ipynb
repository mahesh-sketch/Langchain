{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124d5dce",
   "metadata": {},
   "source": [
    "LangChain allows you to use LLMs (like OpenAI, Gemini, Claude) to generate text or chat responses.\n",
    "\n",
    "LangChain separates:\n",
    "\n",
    "- LLMs → For single-shot completions (plain text response).\n",
    "- Chat Models → For multi-turn conversations (message history, chat roles).\n",
    "\n",
    "Real-life Analogy:\n",
    "Imagine:\n",
    "- An LLM is like Google Search Autocomplete — you input text, it completes it.\n",
    "- A Chat Model is like WhatsApp chat — it remembers who said what and when."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43fd66",
   "metadata": {},
   "source": [
    "# 1. LLM (Single prompt-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b3f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a shared, digital ledger that everyone in a group can see. This ledger records every transaction that happens within the group.\n",
      "\n",
      "Here's the breakdown:\n",
      "\n",
      "*   **Block:** Think of each block as a page in the ledger. It contains a bunch of recent transactions. Once a block is full, it's added to the chain.\n",
      "\n",
      "*   **Chain:**  This is the sequence of blocks, linked together in chronological order. Each new block contains a special code that's based on the previous block, making it incredibly difficult to tamper with the history.\n",
      "\n",
      "*   **Decentralized:** The ledger isn't kept in one central location. Instead, everyone in the group has a copy.  When a new transaction happens, everyone verifies it, and if the majority agrees it's valid, it's added to their copy of the ledger.\n",
      "\n",
      "*   **Secure:** Because the ledger is copied and distributed, changing one copy doesn't affect the others. To change the history, you'd have to change every copy of the ledger, which is practically impossible.\n",
      "\n",
      "**In short:** Blockchain is a secure, transparent, and shared record of transactions. It's like a digital notebook that everyone shares and can trust because it's very hard to cheat.\n",
      "\n",
      "**Analogy:**\n",
      "\n",
      "Think of it like a Google Doc that everyone in your group can view and edit.  Every change is tracked, and everyone has a copy.  If someone tries to secretly change something, everyone else can see it and revert it back.\n",
      "\n",
      "**Common uses:**\n",
      "\n",
      "*   **Cryptocurrencies:**  Like Bitcoin, where blockchain tracks who owns which coins.\n",
      "*   **Supply chain:** Tracking products from origin to consumer.\n",
      "*   **Voting:** Creating a secure and transparent voting system.\n",
      "*   **Healthcare:** Securely storing and sharing medical records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = llm.invoke(\"Explain blockchain in simple terms.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7db837",
   "metadata": {},
   "source": [
    "This works like asking Gemini Flash a single question — good for Q&A, summaries, writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797218b2",
   "metadata": {},
   "source": [
    "# 2. Chat Model (Role-based, memory-style conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a966cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't give you a real-time weather update for Tokyo right now. My information is not connected to live weather data.\n",
      "\n",
      "However, I can tell you how to find the weather in Tokyo:\n",
      "\n",
      "*   **Use a reliable weather app or website:** Popular options include AccuWeather, The Weather Channel, Google Weather (just search \"weather Tokyo\"), and Japan Meteorological Agency (JMA) website.\n",
      "*   **Specify your location:** If you're looking for a specific area within Tokyo (e.g., Shibuya, Shinjuku), include that in your search for a more accurate forecast.\n",
      "\n",
      "When you check the weather, look for the following information:\n",
      "\n",
      "*   **Temperature:** Current temperature, high, and low for the day.\n",
      "*   **Conditions:** Sunny, cloudy, rainy, snowy, etc.\n",
      "*   **Humidity:** How much moisture is in the air.\n",
      "*   **Wind speed and direction:** How strong the wind is and where it's coming from.\n",
      "*   **Chance of precipitation:** The likelihood of rain or snow.\n",
      "\n",
      "Have a great time in Tokyo!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "message = [\n",
    "    HumanMessage(content=\"Hi, who are you ?\"),\n",
    "    AIMessage(content=\"I am your AI assistant\"),\n",
    "    HumanMessage(content=\"Can you tell me about the weather in Tokyo?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(message)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad37893",
   "metadata": {},
   "source": [
    "This gives Gemini the full context of the conversation, useful for chatbots, AI agents, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
