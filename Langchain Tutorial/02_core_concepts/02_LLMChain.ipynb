{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed8707d",
   "metadata": {},
   "source": [
    "An LLMChain in LangChain connects:\n",
    "\n",
    "- A PromptTemplate (your question/instruction),\n",
    "- An LLM (like OpenAI or Gemini),\n",
    "- And executes the prompt with dynamic data.\n",
    "\n",
    "It‚Äôs like a smart assistant pipeline.\n",
    "\n",
    "Real-life Example: Auto Email Reply Assistant: \n",
    "\n",
    "Let‚Äôs say you receive customer queries like:\n",
    "\n",
    "‚ÄúHi, I want to know if your product supports bulk export to Excel.‚Äù\n",
    "\n",
    "You want to auto-generate a polite, professional email response using Gemini.\n",
    "\n",
    "How LLMChain Works in This Case:\n",
    "1. Define a Prompt Template.\n",
    "2. Pass it to the LLM via an LLMChain.\n",
    "3. Fill in user input dynamically and get the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca682f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955167d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22284\\2854121647.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm,prompt=prompt)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22284\\2854121647.py:21: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Email Reply:\n",
      " Subject: Re: Inquiry about Bulk Export to Excel\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "Thank you for your interest in our product and for reaching out to us.\n",
      "\n",
      "Regarding your question about bulk export to Excel, yes, our product does support the ability to export data in bulk to Excel format.\n",
      "\n",
      "[Choose ONE of the following options and include it here, tailoring it to your specific product's functionality:\n",
      "\n",
      "**Option 1 (If it's straightforward):**\n",
      "You can find the bulk export option within the [Specific Section of the Product, e.g., \"Reports\" or \"Data Management\"] section under the \"Export\" button.\n",
      "\n",
      "**Option 2 (If there are specific steps or considerations):**\n",
      "The process for bulk exporting to Excel involves [Briefly outline the key steps, e.g., \"selecting the desired data range and then choosing the 'Export to Excel' option from the menu\"]. Please note that large datasets may take some time to export.\n",
      "\n",
      "**Option 3 (If documentation is helpful):**\n",
      "For detailed instructions on how to perform a bulk export to Excel, please refer to our comprehensive documentation here: [Link to Documentation].\n",
      "\n",
      "**Option 4 (If you need more information to answer accurately):**\n",
      "To ensure I can provide you with the most accurate and helpful information, could you please specify which area of the product you are interested in exporting from?\n",
      "\n",
      "]\n",
      "\n",
      "We hope this information is helpful. Please don't hesitate to contact us if you have any further questions or require additional assistance.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "The [Your Company Name] Support Team\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful email assistant.\n",
    "Given the customer's query: \"{customer_query}\"\n",
    "Write a professional and polite email response addressing their concern.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables= [\"customer_query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "\n",
    "query = \"Hi, I want to know if your product supports bulk export to Excel.\"\n",
    "response = chain.run(query)\n",
    "print(\"ü§ñ Email Reply:\\n\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
