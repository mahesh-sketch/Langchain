{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e88fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f71329",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fcffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f63083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are a knowledgeable AI assistant. Based on the following context, answer the user's question.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\"\"\"\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=['context','question'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a273bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7656\\598012801.py:1: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "W0518 23:35:56.501000 7656 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce07325",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriver = vectorstore.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e2619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7656\\3217261023.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(llm=llm,prompt=custom_prompt)\n"
     ]
    }
   ],
   "source": [
    "qa_chain = LLMChain(llm=llm,prompt=custom_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2fecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_retrieval_qa(query):\n",
    "    # 1. Retrieve docs\n",
    "    docs = retriver.get_relevant_documents(query)\n",
    "    # 2. Join context\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    # 3. Run chain\n",
    "    answer = qa_chain.run({'context':context,'question':query})\n",
    "    \n",
    "    return answer,docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2e2ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7656\\3818667795.py:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa_chain.run({'context':context,'question':query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The Turing test measures the ability of a machine to simulate human conversation.\n",
      "\n",
      "---\n",
      "Used Documents:\n",
      "^ a b Turing's original publication of the Turing test in \"Computing machinery and intelligence\": Turing (1950)\n",
      "Historical influence and philosophical implications: Haugeland (1985, pp. 6–9), Crevier \n",
      "Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"[381] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machin\n",
      "The Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior.[383]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Turing Test?\"\n",
    "answer, used_docs = run_custom_retrieval_qa(query)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n---\\nUsed Documents:\")\n",
    "for doc in used_docs:\n",
    "    print(doc.page_content[:200])  # Print a preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
