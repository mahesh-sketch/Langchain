{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af54b99",
   "metadata": {},
   "source": [
    "LangChain is a framework that helps developers build applications powered by Large Language Models (LLMs). It abstracts away a lot of complexities and lets you:\n",
    "\n",
    "- Chain LLM calls together\n",
    "\n",
    "- Integrate memory\n",
    "\n",
    "- Interact with documents, APIs, tools, databases, and more\n",
    "\n",
    "Think of LangChain as a toolkit for building LLM-based applications like chatbots, document analyzers, assistants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786dcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04e944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langchain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that provides all the necessary building blocks and abstractions to connect LLMs to other data sources and create sophisticated applications.\\n\\nHere\\'s a breakdown of what makes Langchain so useful:\\n\\n**Key Features and Concepts:**\\n\\n*   **LLM Integration:** Langchain makes it easy to connect to various LLMs, including OpenAI\\'s models (GPT-3, GPT-4), open-source models (like Llama 2, Falcon), and hosted solutions like Cohere and AI21 Labs. It provides a standardized interface for interacting with these models, abstracting away the specific API details.\\n\\n*   **Data Connection:** LLMs are powerful, but they\\'re even more useful when they can access and process external data. Langchain provides tools to:\\n    *   **Load data:**  Load data from various sources (text files, PDFs, websites, databases, APIs, etc.).\\n    *   **Transform data:** Clean, split, and format the data for LLM consumption.\\n    *   **Store data:**  Index and store data in vector databases (like Pinecone, Chroma, FAISS) for efficient retrieval based on semantic similarity.\\n\\n*   **Chains:**  A fundamental concept in Langchain.  Chains are sequences of calls to LLMs or other utilities. They allow you to create complex workflows by linking together different components.  For example:\\n    *   **Simple chains:**  A single LLM call to answer a question.\\n    *   **Question Answering chains:**  Load a document, split it into chunks, embed the chunks, and then use an LLM to answer questions based on the retrieved context.\\n    *   **Summarization chains:**  Summarize a long document by iteratively summarizing smaller chunks.\\n\\n*   **Agents:**  Agents take the concept of chains a step further by introducing decision-making capabilities.  An agent uses an LLM to determine which \"tools\" (functions, APIs, etc.) to use to achieve a specific goal.  This allows for more dynamic and autonomous behavior.  For example:\\n    *   An agent could use a search engine to find information, then use a calculator to perform calculations, and finally use an LLM to generate a report based on the results.\\n\\n*   **Memory:**  LLMs are stateless, meaning they don\\'t inherently remember previous interactions. Langchain provides memory modules to maintain context across multiple turns of a conversation or across multiple steps in a chain. This can include:\\n    *   Storing previous messages in a conversation.\\n    *   Summarizing past interactions to provide a concise history.\\n\\n*   **Callbacks:**  Allow you to monitor and debug your Langchain applications. You can use callbacks to log events, track performance, and visualize the execution flow of your chains and agents.\\n\\n*   **Community and Ecosystem:** Langchain has a vibrant and active community, with plenty of resources, tutorials, and example applications available.  It also integrates with other popular tools in the AI/ML ecosystem.\\n\\n**Benefits of Using Langchain:**\\n\\n*   **Abstraction:** Simplifies LLM interaction and data integration, reducing boilerplate code.\\n*   **Modularity:**  Components are designed to be reusable and composable, making it easy to build custom applications.\\n*   **Flexibility:** Supports a wide range of LLMs, data sources, and application types.\\n*   **Rapid Prototyping:**  Provides pre-built chains and agents to quickly get started with common tasks.\\n*   **Scalability:** Designed to handle complex workflows and large datasets.\\n\\n**Use Cases:**\\n\\nLangchain is used for a wide variety of applications, including:\\n\\n*   **Chatbots:**  Building conversational agents that can answer questions, provide support, or automate tasks.\\n*   **Question Answering:**  Creating systems that can answer questions based on a knowledge base of documents.\\n*   **Text Summarization:**  Generating concise summaries of long articles or documents.\\n*   **Code Generation:**  Assisting developers with code generation and debugging.\\n*   **Data Analysis:**  Extracting insights from data using LLMs.\\n*   **Content Creation:**  Generating creative content such as articles, poems, or scripts.\\n*   **Personalized Recommendations:**  Providing personalized recommendations based on user preferences and data.\\n\\n**In Summary:**\\n\\nLangchain is a powerful framework that makes it easier to build applications using large language models. It provides abstractions, components, and tools for connecting LLMs to data, creating chains and agents, managing memory, and monitoring performance.  It\\'s a valuable tool for developers who want to leverage the power of LLMs to create innovative and intelligent applications.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--b4ce260e-9654-41ac-ad08-34d6da0359c2-0'\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = llm.invoke(\"What is Langchain ?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
