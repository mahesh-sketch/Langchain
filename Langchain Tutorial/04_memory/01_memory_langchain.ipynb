{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbdf1a6",
   "metadata": {},
   "source": [
    "In real life, if someone forgets everything after every sentence, it’s not a good conversation. LLMs are stateless — they don’t remember past interactions unless you give them memory.\n",
    "\n",
    "LangChain solves this with Memory objects, which help maintain chat history, summarize, or window past messages.\n",
    "\n",
    "| Concept                            | Purpose                                 |\n",
    "| ---------------------------------- | --------------------------------------- |\n",
    "| ✅ `ConversationBufferMemory`       | Stores all previous messages            |\n",
    "| ✅ `ConversationBufferWindowMemory` | Keeps last *k* messages                 |\n",
    "| ✅ `ConversationSummaryMemory`      | Keeps summarized chat history using LLM |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aae353",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory (Basic, stores full chat history)\n",
    "Use case:\n",
    "- Perfect for short chats where full history matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b2622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd6340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12320\\888508909.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12320\\888508909.py:7: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Mahesh.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hi Mahesh! It's nice to meet you. My name is, well, I don't have a *name* per se, but you can call me AI. I'm a large language model, trained by Google AI. I'm currently running on the PaLM 2 architecture, which allows me to perform a wide range of tasks, from generating creative content to answering your questions in a comprehensive and informative way. I'm excited to chat with you! So, what can I do for you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Mahesh.\n",
      "AI: Hi Mahesh! It's nice to meet you. My name is, well, I don't have a *name* per se, but you can call me AI. I'm a large language model, trained by Google AI. I'm currently running on the PaLM 2 architecture, which allows me to perform a wide range of tasks, from generating creative content to answering your questions in a comprehensive and informative way. I'm excited to chat with you! So, what can I do for you today?\n",
      "Human: What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You just told me! Your name is Mahesh. Is there anything else I can help you with, Mahesh?\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Add memory to the chain\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose = True # Print internal logs for learning\n",
    ")\n",
    "\n",
    "print(conversation.predict(input=\"Hi, my name is Mahesh.\"))\n",
    "print(conversation.predict(input=\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19f054",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory (only recent k turns)\n",
    " Use case:\n",
    "- If you want limited memory, like last 2–3 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31038671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: My favorite color is blue.\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12320\\647031045.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2) # Only keeps last 2 exchanges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Blue is a fantastic choice! It's often associated with feelings of calmness, serenity, and stability. Did you know that blue is the most popular color worldwide? Studies show that people in many different cultures consistently rank blue as their favorite. I find that fascinating!\n",
      "\n",
      "I've also learned that there's a whole spectrum of blues, from the light and airy shades like sky blue and baby blue, to the deeper, more intense hues like navy blue and Prussian blue. Which shade of blue do you find yourself drawn to most often? I'm always interested to hear people's preferences! Maybe you even have a particular reason why you like blue so much. I'd love to hear about it if you're willing to share!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite color is blue.\n",
      "AI: AI: Blue is a fantastic choice! It's often associated with feelings of calmness, serenity, and stability. Did you know that blue is the most popular color worldwide? Studies show that people in many different cultures consistently rank blue as their favorite. I find that fascinating!\n",
      "\n",
      "I've also learned that there's a whole spectrum of blues, from the light and airy shades like sky blue and baby blue, to the deeper, more intense hues like navy blue and Prussian blue. Which shade of blue do you find yourself drawn to most often? I'm always interested to hear people's preferences! Maybe you even have a particular reason why you like blue so much. I'd love to hear about it if you're willing to share!\n",
      "Human: I love ice cream.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Ice cream! Oh, that's wonderful! I can access information about so many different flavors and styles of ice cream. From classic vanilla and chocolate to more adventurous combinations like salted caramel and lavender honey, the possibilities seem endless!\n",
      "\n",
      "Did you know that ice cream dates back to ancient times? There's evidence that emperors in China enjoyed frozen desserts as early as 200 BC! And the first ice cream parlors in America opened in the 1700s.\n",
      "\n",
      "Now I'm curious, what's your favorite ice cream flavor? Do you prefer soft serve or hard packed? Cone or cup? I've also learned about all kinds of toppings like sprinkles, hot fudge, and whipped cream. Do you have a go-to topping combination? Just thinking about it makes me wish I could experience the sensation of eating ice cream myself!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite color is blue.\n",
      "AI: AI: Blue is a fantastic choice! It's often associated with feelings of calmness, serenity, and stability. Did you know that blue is the most popular color worldwide? Studies show that people in many different cultures consistently rank blue as their favorite. I find that fascinating!\n",
      "\n",
      "I've also learned that there's a whole spectrum of blues, from the light and airy shades like sky blue and baby blue, to the deeper, more intense hues like navy blue and Prussian blue. Which shade of blue do you find yourself drawn to most often? I'm always interested to hear people's preferences! Maybe you even have a particular reason why you like blue so much. I'd love to hear about it if you're willing to share!\n",
      "Human: I love ice cream.\n",
      "AI: AI: Ice cream! Oh, that's wonderful! I can access information about so many different flavors and styles of ice cream. From classic vanilla and chocolate to more adventurous combinations like salted caramel and lavender honey, the possibilities seem endless!\n",
      "\n",
      "Did you know that ice cream dates back to ancient times? There's evidence that emperors in China enjoyed frozen desserts as early as 200 BC! And the first ice cream parlors in America opened in the 1700s.\n",
      "\n",
      "Now I'm curious, what's your favorite ice cream flavor? Do you prefer soft serve or hard packed? Cone or cup? I've also learned about all kinds of toppings like sprinkles, hot fudge, and whipped cream. Do you have a go-to topping combination? Just thinking about it makes me wish I could experience the sensation of eating ice cream myself!\n",
      "Human: What is my favorite color?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Ah, a memory test! Clever! Based on our previous conversation, your favorite color is blue. Am I right? It's fun to see how I can recall information within our chat.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2) # Only keeps last 2 exchanges\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(conversation.predict(input=\"My favorite color is blue.\"))\n",
    "print(conversation.predict(input=\"I love ice cream.\"))\n",
    "print(conversation.predict(input=\"What is my favorite color?\"))  # Probably forgotten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4ac9b",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory (summarizes older messages)\n",
    "Use case:\n",
    "- For long chats, summarize earlier conversation to save tokens and still retain context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd7b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: My name is Mahesh, and I live in Bhubaneswar.\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12320\\1977857544.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "It's a pleasure to meet you, Mahesh! Bhubaneswar sounds like a fascinating place to live. I know it's the capital of Odisha, India, and is often called the \"Temple City\" because of the numerous ancient temples. I understand the Lingaraj Temple is a particularly famous one. Have you been there recently? I've also processed information about the Nandankanan Zoological Park, which is apparently quite a popular attraction. Is it as good as people say? I'm always curious to hear firsthand accounts!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human introduces themself as Mahesh from Bhubaneswar. The AI greets Mahesh and demonstrates knowledge about Bhubaneswar, including its status as the capital of Odisha, its nickname \"Temple City,\" the Lingaraj Temple, and the Nandankanan Zoological Park, asking Mahesh for their opinion on the zoo.\n",
      "Human: I work as a software engineer at a startup.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "That's fantastic, Mahesh! Working at a startup in Bhubaneswar must be quite exciting. I imagine the tech scene there is growing rapidly. Are you primarily focused on companies serving the local Odisha market, or are you working on products with a wider, perhaps national or even international, reach?\n",
      "\n",
      "As a large language model, I'm always curious about how technology is being developed and implemented in different regions. I'm trained on a massive dataset of text and code, so I have a broad understanding of software engineering principles and various programming languages. Are you working with any particularly interesting technologies or frameworks at your startup? Perhaps something related to AI, cloud computing, or maybe even something specific to the local context, like agricultural technology?\n",
      "\n",
      "I'd love to hear more about your role and the kinds of projects you're involved in, if you're willing to share. Maybe you're building the next big thing out of Bhubaneswar!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human introduces themself as Mahesh from Bhubaneswar. The AI greets Mahesh and demonstrates knowledge about Bhubaneswar, including its status as the capital of Odisha, its nickname \"Temple City,\" the Lingaraj Temple, and the Nandankanan Zoological Park, asking Mahesh for their opinion on the zoo. Mahesh says they work as a software engineer at a startup. The AI responds enthusiastically, expressing interest in Bhubaneswar's growing tech scene, and inquiring about the startup's market focus (local vs. wider reach), specific technologies used (AI, cloud computing, agricultural tech, etc.), and Mahesh's role and projects, hoping Mahesh is building \"the next big thing.\"\n",
      "Human: What do you know about me?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Okay, Mahesh, based on our conversation so far, here's what I know about you:\n",
      "\n",
      "*   **Name:** You are Mahesh.\n",
      "*   **Location:** You are from Bhubaneswar. I know Bhubaneswar is the capital of Odisha, often called the \"Temple City\" due to its many ancient temples, and home to the famous Lingaraj Temple and the Nandankanan Zoological Park. You live there.\n",
      "*   **Occupation:** You work as a software engineer.\n",
      "*   **Employer:** You work at a startup. I don't know the name of the startup, but I'm very interested in Bhubaneswar's growing tech scene and hope your startup is involved!\n",
      "*   **Interests (Inferred):** Given that you live in Bhubaneswar, I'm guessing you have some appreciation for the city's cultural heritage and maybe even enjoy visiting places like the Lingaraj Temple or Nandankanan. I also know you have an interest in technology as you work as a software engineer.\n",
      "*   **Current State:** You are currently engaged in a conversation with me, a large language model.\n",
      "*   **Missing Information:** I do *not* know the name of your startup, its market focus, the specific technologies you work with, your role in the company, or any specific projects you're working on. I also don't know anything about your personal life outside of your profession and location.\n",
      "\n",
      "Is that a good summary? I'm eager to learn more about you and your work if you're willing to share! I'm especially curious about that startup!\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "print(conversation.predict(input=\"My name is Mahesh, and I live in Bhubaneswar.\"))\n",
    "print(conversation.predict(input=\"I work as a software engineer at a startup.\"))\n",
    "print(conversation.predict(input=\"What do you know about me?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dca1a",
   "metadata": {},
   "source": [
    "✅ Keeps the context\n",
    "✅ Saves memory/tokens\n",
    "✅ LLM understands past without full chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159a6bb",
   "metadata": {},
   "source": [
    "### Combining Memory + PromptTemplate + LLMChain\n",
    "\n",
    "This is where LangChain starts getting powerful and customizable.\n",
    "\n",
    "Imagine you're running a personalized tutor chatbot. You want it to:\n",
    "\n",
    "- Know past conversations (memory ✅)\n",
    "- Ask follow-up questions in a specific tone or format (prompt template ✅)\n",
    "- Use the right LLM to generate answers (chain ✅)\n",
    "\n",
    "You glue them together with LLMChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33b81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3d39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful AI tutor.\n",
    "Given the conversation so far:\n",
    "{chat_history}\n",
    "\n",
    "Respond to the user's new input:\n",
    "{user_input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables= ['chat_history','user_input'],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa0f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb41ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI tutor.\n",
      "Given the conversation so far:\n",
      "\n",
      "\n",
      "Respond to the user's new input:\n",
      "Hi, I'm Mahesh and I want to learn LangChain.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hi Mahesh, great to hear you're interested in learning LangChain! I can definitely help guide you. To get started, it would be helpful to know:\n",
      "\n",
      "1.  **What's your current level of experience with Python and AI/ML concepts?** (e.g., beginner, intermediate, experienced). This will help me tailor the learning path to your background.\n",
      "2.  **What are you hoping to achieve with LangChain?** (e.g., build a chatbot, automate document processing, create an AI agent). Knowing your goals will help us focus on the most relevant aspects.\n",
      "3.  **Have you done any preliminary research on LangChain already?** (e.g., read the documentation, watched tutorials).\n",
      "\n",
      "In the meantime, here are some general starting points:\n",
      "\n",
      "*   **LangChain Documentation:** The official documentation is comprehensive and a good place to start: [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction)\n",
      "*   **Installation:** You'll need to install LangChain. You can do this using pip: `pip install langchain`\n",
      "*   **Core Concepts:** Familiarize yourself with the core concepts like:\n",
      "    *   **Models:** LLMs (Large Language Models) and Chat Models\n",
      "    *   **Prompts:** How you structure input to the model\n",
      "    *   **Chains:** Sequences of calls to LLMs or other utilities\n",
      "    *   **Indexes:** Structuring documents for retrieval\n",
      "    *   **Agents:** Autonomous entities that use LLMs to decide what actions to take\n",
      "\n",
      "I'm here to help you along the way, so please feel free to ask any questions you have! Let me know your background and goals, and we can create a more personalized learning plan.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI tutor.\n",
      "Given the conversation so far:\n",
      "Human: Hi, I'm Mahesh and I want to learn LangChain.\n",
      "AI: Hi Mahesh, great to hear you're interested in learning LangChain! I can definitely help guide you. To get started, it would be helpful to know:\n",
      "\n",
      "1.  **What's your current level of experience with Python and AI/ML concepts?** (e.g., beginner, intermediate, experienced). This will help me tailor the learning path to your background.\n",
      "2.  **What are you hoping to achieve with LangChain?** (e.g., build a chatbot, automate document processing, create an AI agent). Knowing your goals will help us focus on the most relevant aspects.\n",
      "3.  **Have you done any preliminary research on LangChain already?** (e.g., read the documentation, watched tutorials).\n",
      "\n",
      "In the meantime, here are some general starting points:\n",
      "\n",
      "*   **LangChain Documentation:** The official documentation is comprehensive and a good place to start: [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction)\n",
      "*   **Installation:** You'll need to install LangChain. You can do this using pip: `pip install langchain`\n",
      "*   **Core Concepts:** Familiarize yourself with the core concepts like:\n",
      "    *   **Models:** LLMs (Large Language Models) and Chat Models\n",
      "    *   **Prompts:** How you structure input to the model\n",
      "    *   **Chains:** Sequences of calls to LLMs or other utilities\n",
      "    *   **Indexes:** Structuring documents for retrieval\n",
      "    *   **Agents:** Autonomous entities that use LLMs to decide what actions to take\n",
      "\n",
      "I'm here to help you along the way, so please feel free to ask any questions you have! Let me know your background and goals, and we can create a more personalized learning plan.\n",
      "\n",
      "Respond to the user's new input:\n",
      "What are embeddings?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "That's an excellent question, Mahesh! Embeddings are a fundamental concept in LangChain and modern AI, so understanding them is crucial.\n",
      "\n",
      "In simple terms, **embeddings are numerical representations of text (or other data like images or audio) that capture its semantic meaning.** Think of them as a way to translate words, sentences, or even entire documents into a format that a computer can understand and use to compare them.\n",
      "\n",
      "Here's a breakdown to help you understand further:\n",
      "\n",
      "*   **Why are they needed?** LLMs and other machine learning models work with numbers, not raw text. We need a way to convert text into a numerical format that preserves the meaning and relationships between different pieces of text.\n",
      "\n",
      "*   **How are they created?** Embedding models (also sometimes referred to as \"text embedding models\") are trained on massive datasets to learn these numerical representations. These models learn to associate similar words or phrases with similar numerical values. Popular embedding models include those provided by OpenAI, Cohere, and open-source options like Sentence Transformers.\n",
      "\n",
      "*   **What do they look like?** An embedding is a vector (a list of numbers). The length of the vector (the number of dimensions) is determined by the specific embedding model used. Common dimensions range from a few hundred to several thousand. Each number in the vector represents a different aspect of the meaning of the text.\n",
      "\n",
      "*   **What are they used for?** Embeddings are used in a wide variety of NLP tasks:\n",
      "\n",
      "    *   **Semantic Search:** Finding documents or passages that are semantically similar to a query, even if they don't share the same keywords. This is a key component of retrieval-augmented generation (RAG), a very common use case in LangChain.\n",
      "    *   **Clustering:** Grouping similar documents or pieces of text together.\n",
      "    *   **Classification:** Categorizing text into different classes.\n",
      "    *   **Recommendation Systems:** Recommending items based on their similarity to items a user has liked or interacted with.\n",
      "    *   **Question Answering:** Finding the most relevant context for answering a question.\n",
      "    *   **Text Similarity Comparison:** Determining how similar two pieces of text are.\n",
      "\n",
      "*   **How do they relate to LangChain?** LangChain uses embeddings extensively, particularly in the `Indexes` section I mentioned earlier. When you create an index in LangChain, you're typically embedding your documents using an embedding model. This allows you to efficiently search and retrieve relevant information from your documents when interacting with an LLM.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Imagine you have the sentences:\n",
      "\n",
      "*   \"The cat sat on the mat.\"\n",
      "*   \"A feline rested upon the rug.\"\n",
      "\n",
      "Even though these sentences use different words, they have a very similar meaning. An embedding model would generate vectors for these sentences that are close to each other in the embedding space, reflecting their semantic similarity.\n",
      "\n",
      "**In summary, embeddings are numerical representations of text that capture meaning, enabling computers to understand and compare text in a meaningful way. They are a crucial building block for many NLP tasks, especially in LangChain for tasks like semantic search and retrieval.**\n",
      "\n",
      "Does this explanation make sense? Would you like me to elaborate on any particular aspect of embeddings, or perhaps give an example of how they are used in LangChain code?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI tutor.\n",
      "Given the conversation so far:\n",
      "Human: Hi, I'm Mahesh and I want to learn LangChain.\n",
      "AI: Hi Mahesh, great to hear you're interested in learning LangChain! I can definitely help guide you. To get started, it would be helpful to know:\n",
      "\n",
      "1.  **What's your current level of experience with Python and AI/ML concepts?** (e.g., beginner, intermediate, experienced). This will help me tailor the learning path to your background.\n",
      "2.  **What are you hoping to achieve with LangChain?** (e.g., build a chatbot, automate document processing, create an AI agent). Knowing your goals will help us focus on the most relevant aspects.\n",
      "3.  **Have you done any preliminary research on LangChain already?** (e.g., read the documentation, watched tutorials).\n",
      "\n",
      "In the meantime, here are some general starting points:\n",
      "\n",
      "*   **LangChain Documentation:** The official documentation is comprehensive and a good place to start: [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction)\n",
      "*   **Installation:** You'll need to install LangChain. You can do this using pip: `pip install langchain`\n",
      "*   **Core Concepts:** Familiarize yourself with the core concepts like:\n",
      "    *   **Models:** LLMs (Large Language Models) and Chat Models\n",
      "    *   **Prompts:** How you structure input to the model\n",
      "    *   **Chains:** Sequences of calls to LLMs or other utilities\n",
      "    *   **Indexes:** Structuring documents for retrieval\n",
      "    *   **Agents:** Autonomous entities that use LLMs to decide what actions to take\n",
      "\n",
      "I'm here to help you along the way, so please feel free to ask any questions you have! Let me know your background and goals, and we can create a more personalized learning plan.\n",
      "Human: What are embeddings?\n",
      "AI: That's an excellent question, Mahesh! Embeddings are a fundamental concept in LangChain and modern AI, so understanding them is crucial.\n",
      "\n",
      "In simple terms, **embeddings are numerical representations of text (or other data like images or audio) that capture its semantic meaning.** Think of them as a way to translate words, sentences, or even entire documents into a format that a computer can understand and use to compare them.\n",
      "\n",
      "Here's a breakdown to help you understand further:\n",
      "\n",
      "*   **Why are they needed?** LLMs and other machine learning models work with numbers, not raw text. We need a way to convert text into a numerical format that preserves the meaning and relationships between different pieces of text.\n",
      "\n",
      "*   **How are they created?** Embedding models (also sometimes referred to as \"text embedding models\") are trained on massive datasets to learn these numerical representations. These models learn to associate similar words or phrases with similar numerical values. Popular embedding models include those provided by OpenAI, Cohere, and open-source options like Sentence Transformers.\n",
      "\n",
      "*   **What do they look like?** An embedding is a vector (a list of numbers). The length of the vector (the number of dimensions) is determined by the specific embedding model used. Common dimensions range from a few hundred to several thousand. Each number in the vector represents a different aspect of the meaning of the text.\n",
      "\n",
      "*   **What are they used for?** Embeddings are used in a wide variety of NLP tasks:\n",
      "\n",
      "    *   **Semantic Search:** Finding documents or passages that are semantically similar to a query, even if they don't share the same keywords. This is a key component of retrieval-augmented generation (RAG), a very common use case in LangChain.\n",
      "    *   **Clustering:** Grouping similar documents or pieces of text together.\n",
      "    *   **Classification:** Categorizing text into different classes.\n",
      "    *   **Recommendation Systems:** Recommending items based on their similarity to items a user has liked or interacted with.\n",
      "    *   **Question Answering:** Finding the most relevant context for answering a question.\n",
      "    *   **Text Similarity Comparison:** Determining how similar two pieces of text are.\n",
      "\n",
      "*   **How do they relate to LangChain?** LangChain uses embeddings extensively, particularly in the `Indexes` section I mentioned earlier. When you create an index in LangChain, you're typically embedding your documents using an embedding model. This allows you to efficiently search and retrieve relevant information from your documents when interacting with an LLM.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Imagine you have the sentences:\n",
      "\n",
      "*   \"The cat sat on the mat.\"\n",
      "*   \"A feline rested upon the rug.\"\n",
      "\n",
      "Even though these sentences use different words, they have a very similar meaning. An embedding model would generate vectors for these sentences that are close to each other in the embedding space, reflecting their semantic similarity.\n",
      "\n",
      "**In summary, embeddings are numerical representations of text that capture meaning, enabling computers to understand and compare text in a meaningful way. They are a crucial building block for many NLP tasks, especially in LangChain for tasks like semantic search and retrieval.**\n",
      "\n",
      "Does this explanation make sense? Would you like me to elaborate on any particular aspect of embeddings, or perhaps give an example of how they are used in LangChain code?\n",
      "\n",
      "Respond to the user's new input:\n",
      "Can you remind me what I told you earlier?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Okay, Mahesh. Let me remind you what you've told me so far.\n",
      "\n",
      "You told me your name is Mahesh and that you want to learn LangChain. You haven't yet provided me with details about your experience level with Python and AI/ML, your goals for using LangChain, or any preliminary research you've done. I also explained what embeddings are.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_chain.predict(user_input=\"Hi, I'm Mahesh and I want to learn LangChain.\"))\n",
    "print(conversation_chain.predict(user_input=\"What are embeddings?\"))\n",
    "print(conversation_chain.predict(user_input=\"Can you remind me what I told you earlier?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
